IN UNA RETE NEURALE FEED-FORWARD, COME VENGONO ELABORATE LE INFORMAZIONI E COSA IMPLICA L'ASSENZA DI CICLI NEL GRAFO CHE LA RAPPRESENTA?
A) LE INFORMAZIONI SI MUOVONO IN ENTRAMBE LE DIREZIONI; L'ASSENZA DI CICLI ASSICURA LA CAPACITÀ DELLA RETE DI APPRENDERE RELAZIONI COMPLESSE.
B) LE INFORMAZIONI SI MUOVONO IN UNA SOLA DIREZIONE, MA SOLO ALL'INTERNO DELLO STESSO LAYER; L'ASSENZA DI CICLI PERMETTE DI GESTIRE SEQUENZE TEMPORALI.
C) LE INFORMAZIONI SI MUOVONO IN UNA SOLA DIREZIONE, DAI NODI DI UN LAYER A QUELLI DEL LAYER SUCCESSIVO; L'ASSENZA DI CICLI PREVIENE LA RICORSIONE E SEMPLIFICA IL CALCOLO DEL GRADIENTE.
D) LE INFORMAZIONI SI MUOVONO IN MODO CASUALE; L'ASSENZA DI CICLI GARANTISCE UNA MAGGIORE GENERALIZZAZIONE DELLA RETE.
C
COME GESTISCONO LE RNN (RECURRENT NEURAL NETWORKS) LE SEQUENZE DI LUNGHEZZA VARIABILE E QUALI TECNICHE POSSONO ESSERE COMBINATE PER OTTIMIZZARNE L'EFFICACIA?
A) LE RNN NON POSSONO GESTIRE SEQUENZE DI LUNGHEZZA VARIABILE; È NECESSARIO USARE UN MODELLO DIVERSO.
B) LE RNN POSSONO USARE ZERO-PADDING, BUCKETING O UNA COMBINAZIONE DELLE DUE TECNICHE; IL BUCKETING RAGGRUPPA LE SEQUENZE PER LUNGHEZZA, IL ZERO-PADDING LE UNIFORMA.
C) LE RNN USANO SOLO IL BUCKETING; IL ZERO-PADDING GENERA RUMORE.
D) LE RNN USANO SOLO IL ZERO-PADDING; IL BUCKETING RALLENTA L'ADDESTRAMENTO.
B
QUALI SONO LE TRE CAPACITÀ PRINCIPALI DELLE LSTM (LONG SHORT-TERM MEMORY NETWORK) E COME CONTRIBUISCONO ALLA LORO EFFICACIA NEL PROCESSARE SEQUENZE DI DATI?
A) MEMORIZZARE, DIMENTICARE, PREVEDERE; CONSENTONO ALLA RETE DI GESTIRE RELAZIONI A BREVE TERMINE.
B) FOCALIZZARE, MEMORIZZARE, ATTIVARE; CONSENTONO ALLA RETE DI APPRENDERE LE DIPENDENZE SINTATTICHE.
C) DIMENTICARE, SALVARE, FOCALIZZARE; PERMETTONO ALLA RETE DI GESTIRE RELAZIONI A LUNGA DISTANZA, SELEZIONANDO QUALI INFORMAZIONI CONSERVARE E A QUALI PRESTARE ATTENZIONE.
D) RICORDARE, ADATTARE, GENERALIZZARE; CONSENTONO DI GESTIRE SEQUENZE DI LUNGHEZZA VARIABILE.
C
QUAL È L'OBIETTIVO PRINCIPALE DI UN AUTOENCODER SPARSO E COME LO RAGGIUNGE IN TERMINI DI RAPPRESENTAZIONE DEI DATI?
A) RIDURRE LA DIMENSIONALITÀ DEI DATI; PRODUCENDO CODICI DENSI.
B) AUMENTARE LA DIMENSIONALITÀ DEI DATI; USANDO UNA FUNZIONE DI ATTIVAZIONE NON LINEARE.
C) RIDURRE L'OVERFITTING E LA SENSIBILITÀ AL RUMORE; PRODUCENDO CODICI SPARSI CON MOLTI VALORI ZERO IN UNO SPAZIO LATENTE.
D) CLUSTERING DEI DATI; ASSEGNANDO ETICHETTE AI PUNTI IN BASE ALLA LORO VICINANZA NEL CODIFICATO.
C
IN CHE MODO I VARIATIONAL AUTOENCODER (VAE) DIFFERISCONO DAGLI AUTOENCODER TRADIZIONALI E QUAL È UN'APPLICAZIONE TIPICA DI QUESTA CARATTERISTICA?
A) I VAE UTILIZZANO SOLO L'ENCODER; L'APPLICAZIONE TIPICA È LA CLASSIFICAZIONE.
B) I VAE USANO SOLO IL DECODER; L'APPLICAZIONE TIPICA È LA COMPRESSIONE DEI DATI.
C) I VAE RICOSTRUISCONO CAMPIONI DI DATI SIMILI ALL'INPUT; UN'APPLICAZIONE TIPICA È LA COMPUTER GRAFICA PER INSERIRE OGGETTI CON PICCOLE VARIAZIONI IN UNA SCENA.
D) I VAE USANO UNA FUNZIONE DI ATTIVAZIONE LINEARE; LA LORO APPLICAZIONE TIPICA È L'ANALISI DI SEQUENZE.
C
QUAL È IL RUOLO DEL "POSITIONAL ENCODING" IN UN MODELLO TRANSFORMER E PERCHÉ È NECESSARIO?
A) RAPPRESENTARE LE PAROLE IN UNO SPAZIO VETTORIALE; È NECESSARIO PER GESTIRE DATI NON NUMERICI.
B) FORNIRE INFORMAZIONI SULLA POSIZIONE DELLE PAROLE NELLA SEQUENZA; È NECESSARIO PERCHÉ IL TRANSFORMER TRATTA L'INPUT COME VETTORI SENZA CONSIDERARE LA POSIZIONE.
C) NORMALIZZARE I VETTORI DI INPUT; È NECESSARIO PER VELOCIZZARE L'ADDESTRAMENTO.
D) RAPPRESENTARE LE RELAZIONI SEMANTICHE TRA LE PAROLE; È NECESSARIO PER LA TRADUZIONE AUTOMATICA.
B
QUALI SONO LE TRE MATRICI UTILIZZATE NEL MECCANISMO DI ATTENZIONE DI UN TRANSFORMER E A COSA SERVONO?
A) MATRICE DI EMBEDDING, MATRICE DI PESI E MATRICE DI OUTPUT; PER CODIFICARE LE RELAZIONI TRA LE PAROLE.
B) MATRICE DI INPUT, MATRICE DI OUTPUT E MATRICE DI TRASFORMAZIONE; PER LA TRADUZIONE AUTOMATICA.
C) MATRICE DELLE QUERY (Q), MATRICE DELLE CHIAVI (K) E MATRICE DEI VALORI (V); SERVONO A DETERMINARE QUALI PARTI DELLA SEQUENZA DI INPUT SONO RILEVANTI PER OGNI PAROLA.
D) MATRICE DI ATTIVAZIONE, MATRICE DI LOSS E MATRICE DI BACKPROPAGATION; PER L'ADDESTRAMENTO DELLA RETE.
C
QUAL È LA FUNZIONE DELLA MASCHERA DI PADDING E DELLA MASCHERA DI FUTURE ATTENTION IN UN TRANSFORMER?
A) LA MASCHERA DI PADDING SERVE A NORMALIZZARE I PESI, MENTRE LA MASCHERA DI FUTURE ATTENTION SERVE A VELOCIZZARE IL CALCOLO.
B) LA MASCHERA DI PADDING SERVE A EVITARE L'OVERFITTING, MENTRE LA MASCHERA DI FUTURE ATTENTION SERVE AD AUMENTARE LA GENERALIZZAZIONE.
C) LA MASCHERA DI PADDING SERVE A GESTIRE SEQUENZE DI LUNGHEZZA VARIABILE, MENTRE LA MASCHERA DI FUTURE ATTENTION SERVE PER L'AUTO-REGRESSIONE.
D) LA MASCHERA DI PADDING SERVE A CALCOLARE LA LOSS, MENTRE LA MASCHERA DI FUTURE ATTENTION SERVE A CALCOLARE IL GRADIENTE.
C
IN COSA CONSISTE IL MECCANISMO DI MULTI-HEAD ATTENTION IN UN TRANSFORMER E QUAL È IL SUO VANTAGGIO RISPETTO ALL'ATTENZIONE A SINGOLO HEAD?
A) ESEGUIRE L'ATTENZIONE UNA SOLA VOLTA; IL VANTAGGIO È LA VELOCITÀ DI CALCOLO.
B) ESEGUIRE L'ATTENZIONE SU PIÙ SEQUENZE DI INPUT; IL VANTAGGIO È UNA MIGLIORE RAPPRESENTAZIONE DELL'INPUT.
C) ESEGUIRE L'ATTENZIONE IN PARALLELO SU DIVERSE RAPPRESENTAZIONI LINEARI DELL'INPUT; IL VANTAGGIO È LA CAPACITÀ DI CATTURARE DIVERSE DIPENDENZE TRA LE PAROLE.
D) ESEGUIRE L'ATTENZIONE IN MODO RICORSIVO; IL VANTAGGIO È LA CAPACITÀ DI GESTIRE SEQUENZE MOLTO LUNGHE.
C
QUAL È LA DIFFERENZA PRINCIPALE TRA UN LLM GENERATIVO E UN LLM CLASSIFICATORE IN TERMINI DI ARCHITETTURA DEL TRANSFORMER E COMPITI SVOLTI?
A) UN LLM GENERATIVO USA L'ENCODER, MENTRE UN LLM CLASSIFICATORE USA IL DECODER.
B) UN LLM GENERATIVO USA SOLO IL DECODER E PREVEDE IL TOKEN SUCCESSIVO, MENTRE UN LLM CLASSIFICATORE USA SOLO L'ENCODER E CLASSIFICA I TOKEN.
C) UN LLM GENERATIVO CLASSIFICA I TOKEN, MENTRE UN LLM CLASSIFICATORE GENERA IL TESTO.
D) UN LLM GENERATIVO USA SIA ENCODER CHE DECODER, MENTRE UN LLM CLASSIFICATORE USA SOLO L'ENCODER.
B
COME INFLUENZA LA TEMPERATURA LA GENERAZIONE DI TESTO IN UN LLM E QUALI SONO GLI EFFETTI DI UNA TEMPERATURA ALTA O BASSA?
A) LA TEMPERATURA INFLUENZA LA VELOCITÀ DI GENERAZIONE; UNA TEMPERATURA ALTA AUMENTA LA VELOCITÀ.
B) LA TEMPERATURA INFLUENZA IL NUMERO DI PARAMETRI DEL MODELLO; UNA TEMPERATURA BASSA RIDUCE I PARAMETRI.
C) LA TEMPERATURA INFLUENZA LA PROBABILITÀ CON CUI VENGONO SCELTI I TOKEN SUCCESSIVI; UNA TEMPERATURA BASSA GENERA RISPOSTE PIÙ COERENTI E MENO CREATIVE, UNA ALTA RISPOSTE PIÙ VARIE E MENO PREVEDIBILI.
D) LA TEMPERATURA INFLUENZA LA FUNZIONE DI LOSS; UNA TEMPERATURA ALTA MINIMIZZA LA LOSS.
C
QUAL È L'OBIETTIVO PRINCIPALE DELLA FASE DI ESTRAZIONE DI FEATURE NEL PREPROCESSING DEI DATI E PERCHÉ È IMPORTANTE?
A) RIDURRE IL NUMERO DI DATI; È IMPORTANTE PER VELOCIZZARE L'ADDESTRAMENTO.
B) CONVERTIRE I DATI IN UN FORMATO STANDARD; È IMPORTANTE PER LA PORTABILITÀ DEI DATI.
C) ESTRARRE FEATURE SIGNIFICATIVE E FACILI DA INTERPRETARE DAI DATI GREZZI; È IMPORTANTE PERCHÉ LE FEATURE INFLUENZANO L'ANALISI SUCCESSIVA.
D) ELIMINARE IL RUMORE DAI DATI; È IMPORTANTE PER MIGLIORARE L'ACCURATEZZA DEL MODELLO.
C
QUAL È LA DIFFERENZA TRA DISCRETIZZAZIONE CON INTERVALLI EQUI-WIDTH E INTERVALLI EQUI-LOG E QUANDO È PIÙ APPROPRIATO UTILIZZARE CIASCUN METODO?
A) LA DISCRETIZZAZIONE EQUI-WIDTH DIVIDE IN BASE AL LOGARITMO; È PIÙ ADATTA PER I DATI CATEGORIALI.
B) LA DISCRETIZZAZIONE EQUI-LOG DIVIDE IN BASE ALLA LARGHEZZA; È PIÙ ADATTA PER I DATI NUMERICI.
C) LA DISCRETIZZAZIONE EQUI-WIDTH DIVIDE IN INTERVALLI DI UGUALE AMPIEZZA, MENTRE LA DISCRETIZZAZIONE EQUI-LOG DIVIDE IN INTERVALLI IN CUI IL LOGARITMO DELLA DIFFERENZA HA LO STESSO VALORE; LA PRIMA È ADATTA QUANDO I DATI SONO UNIFORMEMENTE DISTRIBUITI, LA SECONDA PER DATI CON VALORI CONCENTRATI IN UN INTERVALLO.
D) LA DISCRETIZZAZIONE EQUI-WIDTH DIVIDE IN BASE A PERCENTILI; È PIÙ ADATTA PER I DATI CON OUTLIER.
C
COME VENGONO USATI I QUANTILI NEL PREPROCESSING DEI DATI E QUALE PROBLEMA AIUTANO A RISOLVERE?
A) PER DIVIDERE I DATI IN CLUSTER; AIUTANO A RAGGRUPPARE I DATI IN BASE ALLA SIMILARITÀ.
B) PER CREARE DELLE FUNZIONI DI ATTIVAZIONE NON LINEARI; AIUTANO A MODELLARE RELAZIONI COMPLESSE.
C) PER CALCOLARE LA MEDIA DEI DATI; AIUTANO A NORMALIZZARE I DATI.
D) PER RILEVARE OUTLIER; AIUTANO A IDENTIFICARE VALORI ANOMALI RISPETTO ALLA DISTRIBUZIONE DEI DATI.
D
QUAL È L'OBIETTIVO DELLA RIDUZIONE DI DIMENSIONALITÀ TRAMITE ROTAZIONE DI ASSI E COME SI REALIZZA IN PRATICA?
A) AUMENTARE LA VARIANZA DEI DATI; SI REALIZZA AGGIUNGENDO NUOVE DIMENSIONI.
B) RIMUOVERE DIMENSIONI CON BASSA VARIANZA; SI REALIZZA ATTRAVERSO UNA ROTAZIONE DEGLI ASSI NELLO SPAZIO DI RAPPRESENTAZIONE DEI DATI.
C) NORMALIZZARE I DATI; SI REALIZZA TRAMITE LA DIVISIONE PER LA DEVIAZIONE STANDARD.
D) CREARE IPERCUBI; SI REALIZZA PROIETTANDO I DATI IN UNO SPAZIO AD ALTA DIMENSIONALITÀ.
B
QUAL È IL RUOLO DELLA SVD (SINGULAR VALUE DECOMPOSITION) NELLA RIDUZIONE DI DIMENSIONALITÀ E QUALI SONO LE SUE VERSIONI RIDOTTE?
A) AUMENTARE IL NUMERO DI DIMENSIONI DEI DATI; LE VERSIONI RIDOTTE NON SONO PIÙ ACCURATE.
B) RUOTARE E TRASFORMARE LO SPAZIO IN UN ELLISSE, I CUI SEMIASSI HANNO LUNGHEZZE PARI AI VALORI SINGOLARI NON NULLI; LE VERSIONI RIDOTTE SONO THIN SVD E COMPACT SVD.
C) RIMUOVERE I DATI RIDONDANTI; LE VERSIONI RIDOTTE SONO PIÙ LENTE.
D) CLUSTERING DEI DATI; LE VERSIONI RIDOTTE NON SONO PIÙ EFFICIENTI.
B
NEL CONTESTO DEL MARKET-BASKET MODEL, COSA RAPPRESENTANO GLI ITEM E I BASKET E COME VENGONO UTILIZZATI?
A) GLI ITEM RAPPRESENTANO LE TRANSAZIONI; I BASKET RAPPRESENTANO GLI OGGETTI ACQUISTATI.
B) GLI ITEM RAPPRESENTANO GLI OGGETTI; I BASKET RAPPRESENTANO LE TRANSAZIONI CHE LI CONTENGONO.
C) GLI ITEM RAPPRESENTANO I CLIENTI; I BASKET RAPPRESENTANO GLI ARTICOLI NEL CARRELLO.
D) GLI ITEM RAPPRESENTANO LE DATE DI ACQUISTO; I BASKET RAPPRESENTANO LE CATEGORIE DEGLI OGGETTI.
B
QUAL È LA DIFFERENZA TRA SUPPORTO, CONFIDENZA E INTERESSE DI UNA REGOLA DI ASSOCIAZIONE E COME VENGONO UTILIZZATI PER VALUTARE L'UTILITÀ DI UNA REGOLA?
A) IL SUPPORTO INDICA LA FREQUENZA DEGLI ITEMSET, LA CONFIDENZA MISURA L'INFLUENZA DI UN ITEM, L'INTERESSE È IL NUMERO DI BASKET; SI USANO PER CALCOLARE LA LOSS.
B) IL SUPPORTO INDICA LA SIMILARITÀ TRA ITEM, LA CONFIDENZA INDICA LA FREQUENZA DI UNA REGOLA, L'INTERESSE INDICA LA FREQUENZA DEGLI ITEM; SI USANO PER IL PREPROCESSING.
C) IL SUPPORTO INDICA LA FREQUENZA CON CUI UN ITEMSET COMPARE NEI BASKET, LA CONFIDENZA INDICA LA PROBABILITÀ CHE UN ITEM SIA PRESENTE IN UN BASKET DATO CHE SONO PRESENTI ALTRI ITEM, L'INTERESSE MISURA QUANTO L'ITEMSET DI SINISTRA INFLUISCE SULLA PRESENZA DELL'ITEM DI DESTRA; SI USANO PER VALUTARE L'UTILITÀ E L'IMPORTANZA DI UNA REGOLA.
D) IL SUPPORTO INDICA LA PROBABILITÀ DI UN ITEMSET, LA CONFIDENZA INDICA L'ACCURATEZZA DELLA CLASSIFICAZIONE, L'INTERESSE INDICA LA SIMILARITÀ TRA LE TUPLE; SI USANO PER IL PRUNING.
C
COME VIENE CALCOLATO IL LIFT DI UNA REGOLA E COSA INDICA UN VALORE DI LIFT MAGGIORE O MINORE DI 1?
A) IL LIFT È DATO DAL RAPPORTO TRA IL SUPPORTO E LA CONFIDENZA; UN VALORE MAGGIORE DI 1 INDICA UNA REGOLA NEGATIVA.
B) IL LIFT È DATO DAL SUPPORTO DELLA REGOLA; UN VALORE MINORE DI 1 INDICA UNA REGOLA POSITIVA.
C) IL LIFT È DATO DAL RAPPORTO TRA IL SUPPORTO OSSERVATO E IL SUPPORTO ATTESO NELL'IPOTESI DI INDIPENDENZA TRA GLI ITEM; UN VALORE MAGGIORE DI 1 INDICA UN'INFLUENZA POSITIVA TRA GLI ITEM, MINORE DI 1 UN'INFLUENZA NEGATIVA.
D) IL LIFT È DATO DALLA DIFFERENZA TRA CONFIDENZA E INTERESSE; UN VALORE MAGGIORE DI 1 INDICA UNA REGOLA PIÙ INTERESSANTE.
C
QUAL È LA DIFFERENZA TRA ITEMSET FREQUENTI MASSIMALI E ITEMSET FREQUENTI CHIUSI E COME SI RELAZIONANO AGLI ITEMSET FREQUENTI STANDARD?
A) GLI ITEMSET MASSIMALI SONO QUELLI CON IL SUPPORTO MAGGIORE, MENTRE QUELLI CHIUSI HANNO SUPPORTO ZERO; SONO ENTRAMBI ITEMSET FREQUENTI.
B) GLI ITEMSET MASSIMALI SONO PIÙ LUNGHI, MENTRE GLI ITEMSET CHIUSI SONO PIÙ CORTI; SONO ENTRAMBI ITEMSET FREQUENTI.
C) UN ITEMSET FREQUENTE È MASSIMALE SE NON ESISTE UN SUO SUPER-INSIEME FREQUENTE, MENTRE UN ITEMSET È CHIUSO SE NON ESISTE UN SUO SUPER-INSIEME CON LO STESSO SUPPORTO; GLI ITEMSET MASSIMALI E CHIUSI SONO ENTRAMBI SOTTOINSIEMI DEGLI ITEMSET FREQUENTI.
D) GLI ITEMSET MASSIMALI HANNO CONFIDENZA MAGGIORE, MENTRE QUELLI CHIUSI HANNO UN LIFT MAGGIORE; SONO ENTRAMBI ITEMSET FREQUENTI.
C
